services:
  qdrant:
    image: qdrant/qdrant:v1.14.1
    container_name: qdrant
    ports:
      - "6333:6333"  # HTTP API
      - "6334:6334"  # gRPC API
    volumes:
      - ./qdrant_data:/qdrant/storage
    environment:
      # gRPC configuration
      - QDRANT__SERVICE__GRPC_PORT=6334
      - QDRANT__SERVICE__ENABLE_TLS=false
      # Performance optimizations
      - QDRANT__STORAGE__PERFORMANCE__MAX_SEARCH_THREADS=0  # Use all available cores
      - QDRANT__STORAGE__PERFORMANCE__MAX_OPTIMIZATION_THREADS=2
      # Optional: increase payload index threshold for better performance
      - QDRANT__STORAGE__OPTIMIZERS__PAYLOAD_INDEX_THRESHOLD=20000
    env_file:
      - .env.prod
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "timeout", "1", "bash", "-c", "</dev/tcp/localhost/6333"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 5s
    # Resource limits (adjust based on your system)
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G
    networks:
      - app_network

  app:
    build: .
    container_name: semantic_open_data_backend
    depends_on:
      qdrant:
        condition: service_healthy
      embedder:
        condition: service_started
      ollama:
        condition: service_healthy
    env_file:
      - .env.prod
    ports:
      - "${API_PORT:-8000}:8000"
    volumes:
      - models_cache:/app/models_cache
    restart: unless-stopped
    # Increase timeout for model loading
#    stop_grace_period: 60s
    networks:
      - app_network
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/health" ]
      interval: 60s
      timeout: 5s
      retries: 3
      start_period: 5s

  embedder:
    image: mskkote/open-data-embedder:latest
    ports:
      - "8080:8080"
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8080/healthz" ]
      interval: 60s
      timeout: 5s
      retries: 3
      start_period: 5s
    networks:
      - app_network

  mongodb:
    image: mongo:7
    container_name: semantic_open_data_mongodb
    restart: unless-stopped
    env_file:
      - .env.prod
    ports:
      - '${MONGO_PORT:-27017}:27017'
    volumes:
      - mongodb_data:/data/db
      - ./mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro
    networks:
      - app_network
    healthcheck:
      test: ['CMD', 'mongosh', '--eval', "db.adminCommand('ping')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  ollama:
      image: ollama/ollama:latest
      container_name: ollama
      ports:
        - "11434:11434"
      volumes:
        - ollama_data:/root/.ollama
        - ./init-ollama.sh:/init-ollama.sh:ro
      environment:
        - OLLAMA_HOST=0.0.0.0
        - OLLAMA_MODELS=gemma3:4b
      restart: unless-stopped
      networks:
        - app_network
      healthcheck:
        test: |
          sh -c "ollama list >/dev/null 2>&1 && \
                 ollama list 2>/dev/null | grep -q gpt-oss"
        interval: 30s
        timeout: 10s
        retries: 10
        start_period: 180s
      deploy:
        resources:
          limits:
            memory: 16G
          reservations:
            memory: 14G
      entrypoint: ["/bin/sh", "/init-ollama.sh"]

networks:
  app_network:
    driver: bridge

volumes:
  models_cache:
  mongodb_data:
  ollama_data:
